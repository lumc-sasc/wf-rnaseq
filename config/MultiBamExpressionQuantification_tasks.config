//Config file for the multibam expression quantification subworkflow processes.
process {
    //Stringtie
    withName: STRINGTIE_STRINGTIE {

        memory = {bam.toList().size() > 1 ?
                8.B * ((bam.target.stream().reduce(0, (x, y) -> x + y.size()) + annotation_gft.target.size()) * task.attempt + (1024*1024*1024)):
                8.B * ((bam.target.size() + annotation_gft.target.size()) * task.attempt + (1024*1024*1024))}

        time = { bam.toList().size() > 1 ?
                    8.ms * ((bam.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) :
                    8.ms * (bam.target.size() * task.attempt / 1000 + 125000)}
        cpus = 2

        errorStrategy = { task.exitStatus in 137..140 ? 'retry' : 'terminate' }
        maxRetries = 3

        ext.prefix = { "${meta.id}_stringtie" }

        ext.args = {"${params.strandedness}" == 'RF' ? '--rf' : "${params.strandedness}" == 'FR' ? '--fr' : ''}
    }



    //gffcompare
    withName: GFFCOMPARE {

        queue = { gtfs.toList().size() > 1 ?
                    (5*((gtfs.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) < 3600000 ? 'short' : 'all') :
                    (5*(gtfs.target.size() * task.attempt / 1000 + 125000) < 3600000 ? 'short' : 'all')}

        memory = {gtfs.toList().size() > 1 ?
                8.B * ((gtfs.target.stream().reduce(0, (x, y) -> x + y.size()) + fasta.target.size() + reference_gtf.target.size()) * task.attempt + (1024*1024*1024)):
                8.B * ((gtfs.target.size() + fasta.target.size() + reference_gtf.target.size()) * task.attempt + (1024*1024*1024))}

        time = { gtfs.toList().size() > 1 ?
                    5.ms * ((gtfs.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) :
                    5.ms * (gfts.target.size() * task.attempt / 1000 + 125000)}
        cpus = 2

        errorStrategy = { task.exitStatus in 137..140 ? 'retry' : 'terminate' }
        maxRetries = 3

        ext.args = '-C'


    }
    


        withName: HTSEQ_COUNT {

        queue = { input.toList().size() > 1 ?
                    (5*((input.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) < 3600000 ? 'short' : 'all') :
                    (5*(input.target.size() * task.attempt / 1000 + 125000) < 3600000 ? 'short' : 'all')}

        memory = {input.toList().size() > 1 ?
                25.B * ((input.target.stream().reduce(0, (x, y) -> x + y.size()) + gtf.target.size()) * task.attempt + (1024*1024*1024)):
                25.B * ((input.target.size() + gtf.target.size()) * task.attempt + (1024*1024*1024))}

        time = { input.toList().size() > 1 ?
                    5.ms * ((input.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) :
                    5.ms * (input.target.size() * task.attempt / 1000 + 125000)}
        cpus = 2

        errorStrategy = { task.exitStatus in 137..140 ? 'retry' : 'terminate' }
        maxRetries = 3

        ext.args = { [
        params.strandedness == 'FR' ? ' -s yes' : params.strandedness == 'RF' ? ' -s reverse' : ' -s no',
        '-r pos'
    ].join(' ').trim() }
    }



    //Collect collumn
    withName: COLLECT_COLUMN {
        publishDir = [path:{"${params.outdir}/final_gene_count/${meta.id}"}, mode: 'copy']


        queue = { abundance.toList().size() > 1 ?
                    (5*((abundance.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) < 3600000 ? 'short' : 'all') :
                    (5*(abundance.target.size() * task.attempt / 1000 + 125000) < 3600000 ? 'short' : 'all')}

        memory = {abundance.toList().size() > 1 ?
                8.B * ((abundance.target.stream().reduce(0, (x, y) -> x + y.size()) + referenceGtf.target.size()) * task.attempt + (1024*1024*1024)):
                8.B * ((abundance.target.size() + referenceGtf.target.size()) * task.attempt + (1024*1024*1024))}

        time = { abundance.toList().size() > 1 ?
                    5.ms * ((abundance.target.stream().reduce(0, (x, y) -> x + y.size())) * task.attempt / 1000 + 125000) :
                    5.ms * (abundance.target.size() * task.attempt / 1000 + 125000)}
        cpus = 2

        errorStrategy = { task.exitStatus in 137..140 ? 'retry' : 'terminate' }
        maxRetries = 3

        ext.args = ''
        ext.prefix = { "${meta.id}_collect_${column}" }


    }

}
